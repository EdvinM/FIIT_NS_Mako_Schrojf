{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Evaluation\n",
    "\n",
    "__2.12.2019__\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment\n",
    "\n",
    "* Ako prvé sa pokúsime vytvoriť NN podobnú VGG. Podľa [WEEK_7 lab](https://github.com/matus-pikuliak/neural_networks_at_fiit/blob/92b24eef8e6444c43a22e8fa51a349b3b1043a7c/week_7/week_7.ipynb), alebo iného tutoriálu\n",
    "* Natrénujeme ju na už predspracovanom datasete\n",
    "* Jej výsledok použijeme ako štartovaciu čiaru\n",
    "* Túto sieť budeme rozširovať o ďalšie vrstvy a parametre\n",
    "* V projekte ponecháme sieť s najlepším skóre\n",
    "* Dole pripájam referenčnú ukážku siete. [Zdroj](https://www.pyimagesearch.com/2019/10/28/3-ways-to-create-a-keras-model-with-tensorflow-2-0-sequential-functional-and-model-subclassing/?__s)\n",
    "\n",
    "**TODO:** Vyuzivame 2 modeli miniVGG a FaceVGG, obrazok modelu, zdroj, popis miniVGG modelu: regresia a categorical_crossentropy, popis modelu VGG-Face\n",
    "\n",
    "Na miesto early stopping vyuzivame `ModelCheckpoint` callback.\n",
    "\n",
    "```\n",
    "loss: 3.9471 - accuracy: 0.0424\n",
    "Epoch 00002: val_loss improved from 3.92091 to 3.52644, saving model to ../models/VGG_FACE_AGE_PREDICT/checkpoints/age_model.hdf5\n",
    "```\n",
    "\n",
    "## Model\n",
    "Použili sme hlboký **VGG-FACE** model, ktorý bol trenovaný na extrakciu 2622 vlastností z tváre [4]. Ako referenčnú implementáciu sme použili implementáciu v Keras [5].\n",
    "\n",
    "![VGG FACE MODEL IMAGE](assets/vgg_face_model.png) Obrázok prevzatý z [4]\n",
    "\n",
    "## Záver\n",
    "...\n",
    "\n",
    "## Reference\n",
    "\n",
    "[1] Rasmus Rothe, Radu Timofte, and Luc Van Gool 2015. DEX: Deep EXpectation of apparent age from a single image. In IEEE International Conference on Computer Vision Workshops (ICCVW).\n",
    "\n",
    "[2] Zakariya Qawaqneh and Arafat Abu Mallouh and Buket D. Barkana 2017. Deep Convolutional Neural Network for Age Estimation based on VGG-Face Model. CoRR, abs/1709.01664.\n",
    "\n",
    "[3] Rasmus Rothe, Radu Timofte, and Luc Van Gool 2016. Deep expectation of real and apparent age from a single image without facial landmarks. International Journal of Computer Vision (IJCV).\n",
    "\n",
    "[4] Omkar M. Parkhi, Andrea Vedaldi, and Andrew Zisserman 2015. Deep Face Recognition. In British Machine Vision Conference.\n",
    "\n",
    "[5] Serengil, S. (2019, July 15). Deep Face Recognition with VGG-Face in Keras. Retrieved from https://sefiks.com/2018/08/06/deep-face-recognition-with-keras/.\n",
    "\n",
    "[6] Rosebrock, A. (2019, November 8). 3 ways to create a Keras model with TensorFlow 2.0 (Sequential, Functional, and Model Subclassing). Retrieved from https://www.pyimagesearch.com/2019/10/28/3-ways-to-create-a-keras-model-with-tensorflow-2-0-sequential-functional-and-model-subclassing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from predict import load_img\n",
    "from predict import softmax_to_age\n",
    "from model import load_trained_model\n",
    "from model import restore_model_from_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "= TRAINED MODEL LOADED FROM DISK\n"
     ]
    }
   ],
   "source": [
    "model = load_trained_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGES = [\n",
    "    '../notebooks/private/tm_1.jpg',\n",
    "    '../notebooks/private/tm_2.jpg',\n",
    "    '../notebooks/private/tm_3.jpg',\n",
    "    '../notebooks/private/tm_4.jpg',\n",
    "    '../notebooks/private/tm_5.jpg',\n",
    "    '../notebooks/private/tm_6.jpg',\n",
    "    '../notebooks/private/tm_7.jpg',\n",
    "    '../notebooks/private/tm_8.jpg',\n",
    "    '../notebooks/private/tm_9.jpg',\n",
    "    '../notebooks/private/tm_10.jpg',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../notebooks/private/tm_1.jpg \tPredicted age: 33.559049487903394 \targmax: 24\n",
      "../notebooks/private/tm_2.jpg \tPredicted age: 34.629214493072595 \targmax: 39\n",
      "../notebooks/private/tm_3.jpg \tPredicted age: 29.638747137083556 \targmax: 21\n",
      "../notebooks/private/tm_4.jpg \tPredicted age: 29.535531576400093 \targmax: 24\n",
      "../notebooks/private/tm_5.jpg \tPredicted age: 43.2430617887876 \targmax: 21\n",
      "../notebooks/private/tm_6.jpg \tPredicted age: 38.3350413996377 \targmax: 21\n",
      "../notebooks/private/tm_7.jpg \tPredicted age: 31.663701504562425 \targmax: 23\n",
      "../notebooks/private/tm_8.jpg \tPredicted age: 35.578515014232835 \targmax: 21\n",
      "../notebooks/private/tm_9.jpg \tPredicted age: 34.728332217084244 \targmax: 24\n",
      "../notebooks/private/tm_10.jpg \tPredicted age: 34.43758629500553 \targmax: 23\n"
     ]
    }
   ],
   "source": [
    "for file_path in IMAGES:\n",
    "    image = np.array([load_img(file_path)])\n",
    "    predictions = model.predict([image])\n",
    "    \n",
    "    apparent_predictions = softmax_to_age(predictions)\n",
    "    prediction = apparent_predictions[0]\n",
    "    \n",
    "    print(file_path, \"\\tPredicted age:\", prediction, \"\\targmax:\", np.argmax(predictions[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
