{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Evaluation\n",
    "\n",
    "__2.12.2019__\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment\n",
    "\n",
    "Všetky experimenty sú popísane v notebooku `Neural_Network`. Trenovanie a vyhodnocovanie modelov je rozpracovné v skriptoch: `train.py`, `model.py` a `predict.py`.\n",
    "\n",
    "### Priebeh experimentov\n",
    "* Ako prvé sa pokúsime vytvoriť NN podobnú VGG. Podľa [WEEK_7 lab](https://github.com/matus-pikuliak/neural_networks_at_fiit/blob/92b24eef8e6444c43a22e8fa51a349b3b1043a7c/week_7/week_7.ipynb), alebo iného tutoriálu\n",
    "* Natrénujeme ju na už predspracovanom datasete\n",
    "* Jej výsledok použijeme ako štartovaciu čiaru\n",
    "* Túto sieť budeme rozširovať o ďalšie vrstvy a parametre\n",
    "* V projekte ponecháme sieť s najlepším skóre\n",
    "* Experiment s miniVGG\n",
    "    * regresiu pre vek a pre pohlavie\n",
    "    * klasifikaciu pre vek a pohlavie\n",
    "* Experiment s FULL-VGG\n",
    "    * klasifikacia veku\n",
    "\n",
    "\n",
    "Na miesto early stopping využívame `ModelCheckpoint` callback.\n",
    "```\n",
    "loss: 3.9471 - accuracy: 0.0424\n",
    "Epoch 00002: val_loss improved from 3.92091 to 3.52644, saving model to ../models/VGG_FACE_AGE_PREDICT/checkpoints/age_model.hdf5\n",
    "```\n",
    "\n",
    "## Model\n",
    "Použili sme hlboký **VGG-FACE** model, ktorý bol trenovaný na extrakciu 2622 vlastností z tváre [4]. Ako referenčnú implementáciu sme použili implementáciu v Keras [5].\n",
    "\n",
    "![VGG FACE MODEL IMAGE](assets/vgg_face_model.png) Obrázok prevzatý z [4]\n",
    "\n",
    "## Záver\n",
    "V našom projekte sme pracovali s dvoma modelmi prvý bol miniVGG [6] a druhý full VGG-Face model [5]. Zistili sme, že najlepšie výsledky dosahuje full VGG model trenovaný ako klasifikácia a predekcie vykonané pomocou regresie. MiniVGG sa učil pomerne rýchlo aj na CPU, ale dosahoval veľmi nízsku spolahlivosť.\n",
    "\n",
    "Ako možné rozšírenia tohto projektu by mohla byť zmena loss funkcie, ktorá zohladňuje odchylku od veku a nie len vek ako kategóriu.\n",
    "\n",
    "## Reference\n",
    "\n",
    "[1] Rasmus Rothe, Radu Timofte, and Luc Van Gool 2015. DEX: Deep EXpectation of apparent age from a single image. In IEEE International Conference on Computer Vision Workshops (ICCVW).\n",
    "\n",
    "[2] Zakariya Qawaqneh and Arafat Abu Mallouh and Buket D. Barkana 2017. Deep Convolutional Neural Network for Age Estimation based on VGG-Face Model. CoRR, abs/1709.01664.\n",
    "\n",
    "[3] Rasmus Rothe, Radu Timofte, and Luc Van Gool 2016. Deep expectation of real and apparent age from a single image without facial landmarks. International Journal of Computer Vision (IJCV).\n",
    "\n",
    "[4] Omkar M. Parkhi, Andrea Vedaldi, and Andrew Zisserman 2015. Deep Face Recognition. In British Machine Vision Conference.\n",
    "\n",
    "[5] Serengil, S. (2019, July 15). Deep Face Recognition with VGG-Face in Keras. Retrieved from https://sefiks.com/2018/08/06/deep-face-recognition-with-keras/.\n",
    "\n",
    "[6] Rosebrock, A. (2019, November 8). 3 ways to create a Keras model with TensorFlow 2.0 (Sequential, Functional, and Model Subclassing). Retrieved from https://www.pyimagesearch.com/2019/10/28/3-ways-to-create-a-keras-model-with-tensorflow-2-0-sequential-functional-and-model-subclassing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from predict import load_img\n",
    "from predict import softmax_to_age\n",
    "from model import load_trained_model\n",
    "from model import restore_model_from_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "= TRAINED MODEL LOADED FROM DISK\n"
     ]
    }
   ],
   "source": [
    "model = load_trained_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "= TRAINED MODEL LOADED FROM DISK\n"
     ]
    }
   ],
   "source": [
    "model = restore_model_from_checkpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGES = [\n",
    "    '../notebooks/private/tm_1.jpg',\n",
    "    '../notebooks/private/tm_2.jpg',\n",
    "    '../notebooks/private/tm_3.jpg',\n",
    "    '../notebooks/private/tm_4.jpg',\n",
    "    '../notebooks/private/tm_5.jpg',\n",
    "    '../notebooks/private/tm_6.jpg',\n",
    "    '../notebooks/private/tm_7.jpg',\n",
    "    '../notebooks/private/tm_8.jpg',\n",
    "    '../notebooks/private/tm_9.jpg',\n",
    "    '../notebooks/private/tm_10.jpg',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../notebooks/private/tm_1.jpg \tPredicted age: 33.559049487903394 \targmax: 24\n",
      "../notebooks/private/tm_2.jpg \tPredicted age: 34.629214493072595 \targmax: 39\n",
      "../notebooks/private/tm_3.jpg \tPredicted age: 29.638747137083556 \targmax: 21\n",
      "../notebooks/private/tm_4.jpg \tPredicted age: 29.535531576400093 \targmax: 24\n",
      "../notebooks/private/tm_5.jpg \tPredicted age: 43.2430617887876 \targmax: 21\n",
      "../notebooks/private/tm_6.jpg \tPredicted age: 38.3350413996377 \targmax: 21\n",
      "../notebooks/private/tm_7.jpg \tPredicted age: 31.663701504562425 \targmax: 23\n",
      "../notebooks/private/tm_8.jpg \tPredicted age: 35.578515014232835 \targmax: 21\n",
      "../notebooks/private/tm_9.jpg \tPredicted age: 34.728332217084244 \targmax: 24\n",
      "../notebooks/private/tm_10.jpg \tPredicted age: 34.43758629500553 \targmax: 23\n"
     ]
    }
   ],
   "source": [
    "for file_path in IMAGES:\n",
    "    image = np.array([load_img(file_path)])\n",
    "    predictions = model.predict([image])\n",
    "    \n",
    "    apparent_predictions = softmax_to_age(predictions)\n",
    "    prediction = apparent_predictions[0]\n",
    "    \n",
    "    print(file_path, \"\\tPredicted age:\", prediction, \"\\targmax:\", np.argmax(predictions[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
