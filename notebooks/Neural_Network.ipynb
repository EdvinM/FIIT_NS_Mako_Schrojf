{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyyaml\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/e8/b3212641ee2718d556df0f23f78de8303f068fe29cdaa7a91018849582fe/PyYAML-5.1.2.tar.gz (265kB)\n",
      "\u001b[K     |████████████████████████████████| 266kB 4.9MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.17.2)\n",
      "Collecting scipy\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/72/a26272b99220804038d8ac4aabe8383cfd969ec548695b0df258058ee919/scipy-1.3.2-cp36-cp36m-manylinux1_x86_64.whl (25.2MB)\n",
      "\u001b[K     |████████████████████████████████| 25.2MB 31.8MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (3.1.1)\n",
      "Requirement already satisfied: ipython in /usr/local/lib/python3.6/dist-packages (7.8.0)\n",
      "Requirement already satisfied: jupyter in /usr/local/lib/python3.6/dist-packages (1.0.0)\n",
      "Collecting pandas\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/52/3f/f6a428599e0d4497e1595030965b5ba455fd8ade6e977e3c819973c4b41d/pandas-0.25.3-cp36-cp36m-manylinux1_x86_64.whl (10.4MB)\n",
      "\u001b[K     |████████████████████████████████| 10.4MB 16.4MB/s eta 0:00:01    |████████████████████▎           | 6.6MB 16.4MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting sympy\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/21/21/f4105795ca7f35c541d82c5b06be684dd2f5cb4f508fb487cd7aea4de776/sympy-1.4-py2.py3-none-any.whl (5.3MB)\n",
      "\u001b[K     |████████████████████████████████| 5.3MB 22.2MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nose\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/15/d8/dd071918c040f50fa1cf80da16423af51ff8ce4a0f2399b7bf8de45ac3d9/nose-1.3.7-py3-none-any.whl (154kB)\n",
      "\u001b[K     |████████████████████████████████| 163kB 39.5MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting opencv-python\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/7e/bd5425f4dacb73367fddc71388a47c1ea570839197c2bcad86478e565186/opencv_python-4.1.1.26-cp36-cp36m-manylinux1_x86_64.whl (28.7MB)\n",
      "\u001b[K     |████████████████████████████████| 28.7MB 28.2MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting opencv-contrib-python\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/33/9b/1f9ef069206002d0bbca80598193904ce1ae2a990e7465bc351b1264c7d8/opencv_contrib_python-4.1.1.26-cp36-cp36m-manylinux1_x86_64.whl (34.7MB)\n",
      "\u001b[K     |████████████████████████████████| 34.7MB 1.2MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting imutils\n",
      "  Downloading https://files.pythonhosted.org/packages/b5/94/46dcae8c061e28be31bcaa55c560cb30ee9403c9a4bb2659768ec1b9eb7d/imutils-0.5.3.tar.gz\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.4.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.8.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: jedi>=0.10 in /usr/local/lib/python3.6/dist-packages (from ipython) (0.15.1)\n",
      "Requirement already satisfied: backcall in /usr/local/lib/python3.6/dist-packages (from ipython) (0.1.0)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython) (0.7.5)\n",
      "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython) (41.2.0)\n",
      "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython) (4.3.2)\n",
      "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython) (4.7.0)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython) (4.4.0)\n",
      "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from ipython) (2.0.9)\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython) (2.4.2)\n",
      "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from jupyter) (5.6.0)\n",
      "Requirement already satisfied: qtconsole in /usr/local/lib/python3.6/dist-packages (from jupyter) (4.5.5)\n",
      "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.6/dist-packages (from jupyter) (6.0.0)\n",
      "Requirement already satisfied: ipykernel in /usr/local/lib/python3.6/dist-packages (from jupyter) (5.1.2)\n",
      "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.6/dist-packages (from jupyter) (7.5.1)\n",
      "Requirement already satisfied: notebook in /usr/local/lib/python3.6/dist-packages (from jupyter) (6.0.1)\n",
      "Collecting pytz>=2017.2 (from pandas)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e7/f9/f0b53f88060247251bf481fa6ea62cd0d25bf1b11a87888e53ce5b7c8ad2/pytz-2019.3-py2.py3-none-any.whl (509kB)\n",
      "\u001b[K     |████████████████████████████████| 512kB 29.4MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting mpmath>=0.19 (from sympy)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/63/3384ebb3b51af9610086b23ea976e6d27d6d97bf140a76a365bd77a3eb32/mpmath-1.1.0.tar.gz (512kB)\n",
      "\u001b[K     |████████████████████████████████| 522kB 29.5MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.1->matplotlib) (1.11.0)\n",
      "Requirement already satisfied: parso>=0.5.0 in /usr/local/lib/python3.6/dist-packages (from jedi>=0.10->ipython) (0.5.1)\n",
      "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython) (0.2.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython) (0.6.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython) (0.1.7)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter) (1.4.2)\n",
      "Requirement already satisfied: nbformat>=4.4 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter) (4.4.0)\n",
      "Requirement already satisfied: jinja2>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter) (2.10.1)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter) (0.8.4)\n",
      "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter) (0.4.2)\n",
      "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter) (0.6.0)\n",
      "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter) (4.5.0)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter) (0.3)\n",
      "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter) (3.1.0)\n",
      "Requirement already satisfied: jupyter-client>=4.1 in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter) (5.3.3)\n",
      "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipykernel->jupyter) (6.0.3)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->jupyter) (3.5.1)\n",
      "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter) (1.5.0)\n",
      "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter) (0.8.2)\n",
      "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter) (0.7.1)\n",
      "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter) (18.1.0)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.4->nbconvert->jupyter) (3.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2>=2.4->nbconvert->jupyter) (1.1.1)\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->jupyter) (0.5.1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.4->nbconvert->jupyter) (19.2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyrsistent>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.4->nbconvert->jupyter) (0.15.4)\n",
      "Building wheels for collected packages: pyyaml, imutils, mpmath\n",
      "  Building wheel for pyyaml (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyyaml: filename=PyYAML-5.1.2-cp36-cp36m-linux_x86_64.whl size=45393 sha256=aaf6725e2e693cdfa305c5742c54b522d3bb503be8370354071dda92d0568700\n",
      "  Stored in directory: /root/.cache/pip/wheels/d9/45/dd/65f0b38450c47cf7e5312883deb97d065e030c5cca0a365030\n",
      "  Building wheel for imutils (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for imutils: filename=imutils-0.5.3-cp36-none-any.whl size=26734 sha256=d8a837b0849f7e111ee2aeb7c46ed429e7ebf5f9b57253211963b4bf889eb9fc\n",
      "  Stored in directory: /root/.cache/pip/wheels/16/84/1f/bf88641293cda2c8be81a5c4b8ca973dd9125a6dc3767417fd\n",
      "  Building wheel for mpmath (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for mpmath: filename=mpmath-1.1.0-cp36-none-any.whl size=532006 sha256=4bf41778a0dd8d674b142ed6212ec02a1d5754a31cc9882dd0123eb6ce2b431a\n",
      "  Stored in directory: /root/.cache/pip/wheels/63/9d/8e/37c3f6506ed3f152733a699e92d8e0c9f5e5f01dea262f80ad\n",
      "Successfully built pyyaml imutils mpmath\n",
      "Installing collected packages: pyyaml, scipy, pytz, pandas, mpmath, sympy, nose, opencv-python, opencv-contrib-python, imutils\n",
      "Successfully installed imutils-0.5.3 mpmath-1.1.0 nose-1.3.7 opencv-contrib-python-4.1.1.26 opencv-python-4.1.1.26 pandas-0.25.3 pytz-2019.3 pyyaml-5.1.2 scipy-1.3.2 sympy-1.4\n",
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pyyaml numpy scipy matplotlib ipython jupyter pandas sympy nose opencv-python opencv-contrib-python imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "\n",
    "import yaml\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.01, 'batch_size': 16, 'num_hidden_layers': 4}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hparams = yaml.safe_load(open('../src/models/hparams.yaml'))\n",
    "\n",
    "hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_path</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>img_array</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17/10000217_1981-05-05_2009.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28</td>\n",
       "      <td>[255 255 255 ... 144  78  27]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12/100012_1948-07-03_2008.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60</td>\n",
       "      <td>[92 98 93 ... 35 31 30]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16/10002116_1971-05-31_2012.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41</td>\n",
       "      <td>[ 10  30  61 ... 231 237 255]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>02/10002702_1960-11-09_2012.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52</td>\n",
       "      <td>[178 122  97 ... 168 112  83]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41/10003541_1937-09-27_1971.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34</td>\n",
       "      <td>[194 189 190 ... 101 103 104]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         full_path  gender  age                      img_array\n",
       "0  17/10000217_1981-05-05_2009.jpg     1.0   28  [255 255 255 ... 144  78  27]\n",
       "1    12/100012_1948-07-03_2008.jpg     1.0   60        [92 98 93 ... 35 31 30]\n",
       "2  16/10002116_1971-05-31_2012.jpg     0.0   41  [ 10  30  61 ... 231 237 255]\n",
       "3  02/10002702_1960-11-09_2012.jpg     0.0   52  [178 122  97 ... 168 112  83]\n",
       "4  41/10003541_1937-09-27_1971.jpg     1.0   34  [194 189 190 ... 101 103 104]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# todo: change this to binary format.\n",
    "\n",
    "wiki_df = pd.read_csv('../data/processed/wiki_df.csv', sep=';')\n",
    "\n",
    "wiki_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_df = wiki_df.drop(['img_array'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len 1412\n",
      "i (array([[[[1.        , 1.        , 1.        ],\n",
      "         [1.        , 1.        , 1.        ],\n",
      "         [1.        , 1.        , 1.        ],\n",
      "         ...,\n",
      "         [0.32941177, 0.34117648, 0.3764706 ],\n",
      "         [0.34509805, 0.35686275, 0.39215687],\n",
      "         [0.3647059 , 0.3764706 , 0.4117647 ]],\n",
      "\n",
      "        [[1.        , 1.        , 1.        ],\n",
      "         [1.        , 1.        , 1.        ],\n",
      "         [1.        , 1.        , 1.        ],\n",
      "         ...,\n",
      "         [0.3254902 , 0.3372549 , 0.37254903],\n",
      "         [0.34117648, 0.3529412 , 0.3882353 ],\n",
      "         [0.36862746, 0.38039216, 0.41568628]],\n",
      "\n",
      "        [[1.        , 1.        , 1.        ],\n",
      "         [1.        , 1.        , 1.        ],\n",
      "         [1.        , 1.        , 1.        ],\n",
      "         ...,\n",
      "         [0.32156864, 0.33333334, 0.36862746],\n",
      "         [0.34117648, 0.3529412 , 0.3882353 ],\n",
      "         [0.37254903, 0.38431373, 0.41960785]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.16862746, 0.30980393, 0.52156866],\n",
      "         [0.1254902 , 0.27058825, 0.48235294],\n",
      "         [0.11764706, 0.2627451 , 0.4745098 ],\n",
      "         ...,\n",
      "         [0.04705882, 0.29803923, 0.5411765 ],\n",
      "         [0.06666667, 0.30588236, 0.5529412 ],\n",
      "         [0.08627451, 0.2901961 , 0.54901963]],\n",
      "\n",
      "        [[0.16470589, 0.30980393, 0.52156866],\n",
      "         [0.11372549, 0.25882354, 0.46666667],\n",
      "         [0.10196079, 0.24705882, 0.45490196],\n",
      "         ...,\n",
      "         [0.07450981, 0.31764707, 0.56078434],\n",
      "         [0.08235294, 0.30980393, 0.56078434],\n",
      "         [0.10980392, 0.30980393, 0.5686275 ]],\n",
      "\n",
      "        [[0.16078432, 0.29803923, 0.50980395],\n",
      "         [0.14901961, 0.28627452, 0.49803922],\n",
      "         [0.11764706, 0.25490198, 0.46666667],\n",
      "         ...,\n",
      "         [0.07843138, 0.2901961 , 0.54901963],\n",
      "         [0.09411765, 0.29803923, 0.5568628 ],\n",
      "         [0.10588235, 0.30588236, 0.5647059 ]]],\n",
      "\n",
      "\n",
      "       [[[0.3647059 , 0.38431373, 0.36078432],\n",
      "         [0.34901962, 0.36862746, 0.3529412 ],\n",
      "         [0.34901962, 0.36862746, 0.3529412 ],\n",
      "         ...,\n",
      "         [0.42352942, 0.4392157 , 0.44313726],\n",
      "         [0.42352942, 0.4392157 , 0.44313726],\n",
      "         [0.42352942, 0.4392157 , 0.44313726]],\n",
      "\n",
      "        [[0.3529412 , 0.37254903, 0.34901962],\n",
      "         [0.36078432, 0.38039216, 0.3647059 ],\n",
      "         [0.36862746, 0.3882353 , 0.37254903],\n",
      "         ...,\n",
      "         [0.41568628, 0.43137255, 0.43529412],\n",
      "         [0.41568628, 0.43137255, 0.43529412],\n",
      "         [0.41568628, 0.43137255, 0.43529412]],\n",
      "\n",
      "        [[0.34509805, 0.3647059 , 0.34117648],\n",
      "         [0.36078432, 0.38039216, 0.3647059 ],\n",
      "         [0.3647059 , 0.38431373, 0.36862746],\n",
      "         ...,\n",
      "         [0.4117647 , 0.42745098, 0.43137255],\n",
      "         [0.4117647 , 0.42745098, 0.43137255],\n",
      "         [0.4117647 , 0.42745098, 0.43137255]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.09019608, 0.11372549, 0.16078432],\n",
      "         [0.09019608, 0.10196079, 0.14117648],\n",
      "         [0.11764706, 0.12156863, 0.14509805],\n",
      "         ...,\n",
      "         [0.11764706, 0.12156863, 0.13725491],\n",
      "         [0.11764706, 0.12156863, 0.13725491],\n",
      "         [0.11764706, 0.12156863, 0.13725491]],\n",
      "\n",
      "        [[0.09019608, 0.11372549, 0.16078432],\n",
      "         [0.08627451, 0.10196079, 0.14117648],\n",
      "         [0.11764706, 0.12156863, 0.14509805],\n",
      "         ...,\n",
      "         [0.11764706, 0.12156863, 0.13725491],\n",
      "         [0.11764706, 0.12156863, 0.13725491],\n",
      "         [0.11764706, 0.12156863, 0.13725491]],\n",
      "\n",
      "        [[0.09019608, 0.11372549, 0.16078432],\n",
      "         [0.08627451, 0.10196079, 0.14117648],\n",
      "         [0.11764706, 0.12156863, 0.14509805],\n",
      "         ...,\n",
      "         [0.11764706, 0.12156863, 0.13725491],\n",
      "         [0.11764706, 0.12156863, 0.13725491],\n",
      "         [0.11764706, 0.12156863, 0.13725491]]],\n",
      "\n",
      "\n",
      "       [[[0.23921569, 0.11764706, 0.03921569],\n",
      "         [0.23921569, 0.11764706, 0.03921569],\n",
      "         [0.23921569, 0.11764706, 0.03921569],\n",
      "         ...,\n",
      "         [0.21568628, 0.07450981, 0.01960784],\n",
      "         [0.21568628, 0.07450981, 0.02352941],\n",
      "         [0.21568628, 0.07058824, 0.03529412]],\n",
      "\n",
      "        [[0.23921569, 0.11764706, 0.03921569],\n",
      "         [0.23921569, 0.11764706, 0.03921569],\n",
      "         [0.23921569, 0.11764706, 0.03921569],\n",
      "         ...,\n",
      "         [0.22352941, 0.08235294, 0.02745098],\n",
      "         [0.22745098, 0.08627451, 0.03529412],\n",
      "         [0.23137255, 0.08627451, 0.04705882]],\n",
      "\n",
      "        [[0.24313726, 0.11764706, 0.03921569],\n",
      "         [0.24313726, 0.11764706, 0.03921569],\n",
      "         [0.24313726, 0.11764706, 0.03921569],\n",
      "         ...,\n",
      "         [0.23137255, 0.09019608, 0.03529412],\n",
      "         [0.24313726, 0.10196079, 0.05098039],\n",
      "         [0.24313726, 0.10196079, 0.05882353]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.45882353, 0.25490198, 0.10196079],\n",
      "         [0.4627451 , 0.25882354, 0.10196079],\n",
      "         [0.4627451 , 0.25882354, 0.10196079],\n",
      "         ...,\n",
      "         [1.        , 0.92941177, 0.9137255 ],\n",
      "         [1.        , 0.92941177, 0.9137255 ],\n",
      "         [1.        , 0.92941177, 0.9137255 ]],\n",
      "\n",
      "        [[0.4627451 , 0.25882354, 0.10196079],\n",
      "         [0.4627451 , 0.25882354, 0.10196079],\n",
      "         [0.4627451 , 0.25882354, 0.10196079],\n",
      "         ...,\n",
      "         [1.        , 0.92941177, 0.9098039 ],\n",
      "         [1.        , 0.92941177, 0.9098039 ],\n",
      "         [1.        , 0.92941177, 0.9098039 ]],\n",
      "\n",
      "        [[0.4627451 , 0.25882354, 0.10196079],\n",
      "         [0.4627451 , 0.25882354, 0.10196079],\n",
      "         [0.4627451 , 0.25882354, 0.10196079],\n",
      "         ...,\n",
      "         [1.        , 0.92941177, 0.90588236],\n",
      "         [1.        , 0.92941177, 0.90588236],\n",
      "         [1.        , 0.92941177, 0.90588236]]],\n",
      "\n",
      "\n",
      "       ...,\n",
      "\n",
      "\n",
      "       [[[0.8509804 , 0.6862745 , 0.6901961 ],\n",
      "         [0.85490197, 0.6901961 , 0.69411767],\n",
      "         [0.8627451 , 0.7019608 , 0.7058824 ],\n",
      "         ...,\n",
      "         [0.88235295, 0.9019608 , 0.9254902 ],\n",
      "         [0.88235295, 0.8980392 , 0.93333334],\n",
      "         [0.8862745 , 0.9019608 , 0.9372549 ]],\n",
      "\n",
      "        [[0.8392157 , 0.68235296, 0.68235296],\n",
      "         [0.84313726, 0.6862745 , 0.6862745 ],\n",
      "         [0.85882354, 0.7019608 , 0.7058824 ],\n",
      "         ...,\n",
      "         [0.8745098 , 0.89411765, 0.91764706],\n",
      "         [0.8745098 , 0.89411765, 0.91764706],\n",
      "         [0.8784314 , 0.89411765, 0.92941177]],\n",
      "\n",
      "        [[0.827451  , 0.6745098 , 0.67058825],\n",
      "         [0.827451  , 0.6862745 , 0.6784314 ],\n",
      "         [0.84705883, 0.7019608 , 0.7019608 ],\n",
      "         ...,\n",
      "         [0.8627451 , 0.88235295, 0.9019608 ],\n",
      "         [0.8666667 , 0.88235295, 0.9019608 ],\n",
      "         [0.87058824, 0.88235295, 0.9137255 ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.03529412, 0.04705882, 0.07450981],\n",
      "         [0.03529412, 0.05490196, 0.07843138],\n",
      "         [0.03921569, 0.05098039, 0.07843138],\n",
      "         ...,\n",
      "         [0.0627451 , 0.07843138, 0.12156863],\n",
      "         [0.05490196, 0.07058824, 0.11372549],\n",
      "         [0.04705882, 0.0627451 , 0.10980392]],\n",
      "\n",
      "        [[0.01176471, 0.02745098, 0.0627451 ],\n",
      "         [0.01960784, 0.03529412, 0.07058824],\n",
      "         [0.03137255, 0.04705882, 0.08235294],\n",
      "         ...,\n",
      "         [0.0627451 , 0.07450981, 0.1254902 ],\n",
      "         [0.05490196, 0.07058824, 0.11764706],\n",
      "         [0.04705882, 0.0627451 , 0.10980392]],\n",
      "\n",
      "        [[0.        , 0.01568628, 0.05098039],\n",
      "         [0.01176471, 0.02745098, 0.0627451 ],\n",
      "         [0.02745098, 0.04313726, 0.07843138],\n",
      "         ...,\n",
      "         [0.0627451 , 0.07843138, 0.1254902 ],\n",
      "         [0.05490196, 0.07058824, 0.11764706],\n",
      "         [0.04705882, 0.0627451 , 0.10980392]]],\n",
      "\n",
      "\n",
      "       [[[0.93333334, 0.93333334, 0.9411765 ],\n",
      "         [0.9372549 , 0.9372549 , 0.94509804],\n",
      "         [0.9372549 , 0.9372549 , 0.94509804],\n",
      "         ...,\n",
      "         [0.13333334, 0.09803922, 0.07843138],\n",
      "         [0.11764706, 0.08235294, 0.0627451 ],\n",
      "         [0.11764706, 0.08235294, 0.0627451 ]],\n",
      "\n",
      "        [[0.93333334, 0.93333334, 0.9411765 ],\n",
      "         [0.9372549 , 0.9372549 , 0.94509804],\n",
      "         [0.9372549 , 0.9372549 , 0.94509804],\n",
      "         ...,\n",
      "         [0.10980392, 0.07450981, 0.05490196],\n",
      "         [0.11764706, 0.08235294, 0.0627451 ],\n",
      "         [0.12156863, 0.09019608, 0.07058824]],\n",
      "\n",
      "        [[0.93333334, 0.93333334, 0.9411765 ],\n",
      "         [0.9372549 , 0.9372549 , 0.94509804],\n",
      "         [0.9372549 , 0.9372549 , 0.94509804],\n",
      "         ...,\n",
      "         [0.1254902 , 0.09019608, 0.07058824],\n",
      "         [0.11372549, 0.07843138, 0.05882353],\n",
      "         [0.10980392, 0.07450981, 0.05490196]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.22745098, 0.18431373, 0.16862746],\n",
      "         [0.25490198, 0.21176471, 0.19607843],\n",
      "         [0.19607843, 0.15294118, 0.14509805],\n",
      "         ...,\n",
      "         [0.21176471, 0.16862746, 0.18431373],\n",
      "         [0.29803923, 0.25882354, 0.28235295],\n",
      "         [0.27450982, 0.23137255, 0.25490198]],\n",
      "\n",
      "        [[0.19215687, 0.14901961, 0.13333334],\n",
      "         [0.21176471, 0.16862746, 0.15294118],\n",
      "         [0.18431373, 0.14117648, 0.13333334],\n",
      "         ...,\n",
      "         [0.19607843, 0.15294118, 0.16078432],\n",
      "         [0.2627451 , 0.21960784, 0.23529412],\n",
      "         [0.25490198, 0.21176471, 0.23529412]],\n",
      "\n",
      "        [[0.20392157, 0.16078432, 0.14509805],\n",
      "         [0.2       , 0.15686275, 0.14117648],\n",
      "         [0.18431373, 0.14117648, 0.13333334],\n",
      "         ...,\n",
      "         [0.18431373, 0.14117648, 0.14509805],\n",
      "         [0.22745098, 0.18039216, 0.19215687],\n",
      "         [0.25882354, 0.21176471, 0.23137255]]],\n",
      "\n",
      "\n",
      "       [[[0.05882353, 0.05882353, 0.05882353],\n",
      "         [0.08627451, 0.08627451, 0.08627451],\n",
      "         [0.07450981, 0.07450981, 0.07450981],\n",
      "         ...,\n",
      "         [0.13725491, 0.13725491, 0.13725491],\n",
      "         [0.20784314, 0.20784314, 0.20784314],\n",
      "         [0.23529412, 0.23529412, 0.23529412]],\n",
      "\n",
      "        [[0.06666667, 0.06666667, 0.06666667],\n",
      "         [0.07058824, 0.07058824, 0.07058824],\n",
      "         [0.05098039, 0.05098039, 0.05098039],\n",
      "         ...,\n",
      "         [0.13725491, 0.13725491, 0.13725491],\n",
      "         [0.1764706 , 0.1764706 , 0.1764706 ],\n",
      "         [0.23921569, 0.23921569, 0.23921569]],\n",
      "\n",
      "        [[0.0627451 , 0.0627451 , 0.0627451 ],\n",
      "         [0.05882353, 0.05882353, 0.05882353],\n",
      "         [0.05098039, 0.05098039, 0.05098039],\n",
      "         ...,\n",
      "         [0.15294118, 0.15294118, 0.15294118],\n",
      "         [0.1764706 , 0.1764706 , 0.1764706 ],\n",
      "         [0.22352941, 0.22352941, 0.22352941]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.1882353 , 0.1882353 , 0.1882353 ],\n",
      "         [0.20392157, 0.20392157, 0.20392157],\n",
      "         [0.18431373, 0.18431373, 0.18431373],\n",
      "         ...,\n",
      "         [0.3882353 , 0.3882353 , 0.3882353 ],\n",
      "         [0.3764706 , 0.3764706 , 0.3764706 ],\n",
      "         [0.36862746, 0.36862746, 0.36862746]],\n",
      "\n",
      "        [[0.1764706 , 0.1764706 , 0.1764706 ],\n",
      "         [0.2       , 0.2       , 0.2       ],\n",
      "         [0.18039216, 0.18039216, 0.18039216],\n",
      "         ...,\n",
      "         [0.36862746, 0.36862746, 0.36862746],\n",
      "         [0.3647059 , 0.3647059 , 0.3647059 ],\n",
      "         [0.3254902 , 0.3254902 , 0.3254902 ]],\n",
      "\n",
      "        [[0.1882353 , 0.1882353 , 0.1882353 ],\n",
      "         [0.18039216, 0.18039216, 0.18039216],\n",
      "         [0.16862746, 0.16862746, 0.16862746],\n",
      "         ...,\n",
      "         [0.4117647 , 0.4117647 , 0.4117647 ],\n",
      "         [0.40784314, 0.40784314, 0.40784314],\n",
      "         [0.36078432, 0.36078432, 0.36078432]]]], dtype=float32), array([28, 60, 41, 52, 34, 42, 36, 23, 25, 37, 78, 42, 33, 28, 60, 13]))\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "class WIKISequence(Sequence):\n",
    "    \"\"\"Base object for fitting to a sequence of data, such as a dataset.\n",
    "    Every `Sequence` must implement the `__getitem__` and the `__len__` methods.\n",
    "    If you want to modify your dataset between epochs you may implement\n",
    "    `on_epoch_end`.\n",
    "    The method `__getitem__` should return a complete batch.\n",
    "\n",
    "    Example: https://www.tensorflow.org/api_docs/python/tf/keras/utils/Sequence\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dataset_df, batch_size, base_path = '../data/raw/wiki_crop/'):\n",
    "        self.base_path = base_path\n",
    "        self.dataset_df = dataset_df\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def load_img(self, file_path):\n",
    "        \"\"\"Load single image from disk and resize and convert to np array\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        im = cv2.imread(self.base_path + file_path)\n",
    "        im = cv2.resize(im, (224, 224), interpolation=cv2.INTER_LINEAR)\n",
    "        im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "        return (np.array(im) / 255.0).astype(np.float32)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Gets batch at position `index`.\n",
    "        Arguments:\n",
    "            index: position of the batch in the Sequence.\n",
    "        Returns:\n",
    "            A batch\n",
    "        \"\"\"\n",
    "        batch_df = self.dataset_df[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "\n",
    "        return np.array([self.load_img(full_path) for full_path in batch_df['full_path']]), np.array(batch_df['age'])\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batch in the Sequence.\n",
    "        Returns:\n",
    "            The number of batches in the Sequence.\n",
    "        \"\"\"\n",
    "        return math.ceil(len(self.dataset_df) / self.batch_size)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        \"\"\"Method called at the end of every epoch.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "wiki_generator = WIKISequence(wiki_df, 16)\n",
    "    \n",
    "print(\"len\", len(wiki_generator))\n",
    "print(\"i\", wiki_generator[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Noramalize image values on range <0.0;1.0>\n",
    "# check: https://www.tensorflow.org/tutorials/images/cnn\n",
    "#wiki_df['img_array'] = wiki_df['img_array'] / 255.0\n",
    "#wiki_df['img_array'] = wiki_df['full_path'].apply(lambda x: np.array(cv2.resize(cv2.imread('../data/raw/wiki_crop/' + x), (224, 224), interpolation=cv2.INTER_LINEAR).reshape(1, -1)[0]))\n",
    "\n",
    "# TODO CHECK:\n",
    "# wiki_df['img_array'] = wiki_df['full_path'].apply(lambda x: cv2.resize(cv2.imread('../data/raw/wiki_crop/' + x), (224, 224), interpolation=cv2.INTER_LINEAR).reshape(1, -1)[0])\n",
    "\n",
    "wiki_df = wiki_df.drop(['img_array'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1\n",
    "\n",
    "* Ako prvé sa pokúsime vytvoriť NN podobnú VGG. Podľa [WEEK_7 lab](https://github.com/matus-pikuliak/neural_networks_at_fiit/blob/92b24eef8e6444c43a22e8fa51a349b3b1043a7c/week_7/week_7.ipynb), alebo iného tutoriálu\n",
    "* Natrénujeme ju na už predspracovanom datasete\n",
    "* Jej výsledok pou%zijeme ako štartovaciu čiaru\n",
    "* Túto sieť budeme rozširovať o ďalšie vrstvy a parametre\n",
    "* V projekte ponecháme sieť s najlepším skóre\n",
    "* Dole pripájam referenčnú ukážku siete. [Zdroj](https://www.pyimagesearch.com/2019/10/28/3-ways-to-create-a-keras-model-with-tensorflow-2-0-sequential-functional-and-model-subclassing/?__s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, Dense, MaxPooling2D, Flatten\n",
    "from tensorflow.keras.layers import Activation, BatchNormalization, Dropout\n",
    "\n",
    "\n",
    "class MiniVGGNetModel(keras.Model):\n",
    "    def __init__(self, classes, chanDim=-1):\n",
    "        # call the parent constructor\n",
    "        super(MiniVGGNetModel, self).__init__()\n",
    "\n",
    "        # initialize the layers in the first (CONV => RELU) * 2 => POOL\n",
    "        # layer set\n",
    "        self.conv1A = Conv2D(32, (3, 3), padding=\"same\")\n",
    "        self.act1A = Activation(\"relu\")\n",
    "        self.bn1A = BatchNormalization(axis=chanDim)\n",
    "        self.conv1B = Conv2D(32, (3, 3), padding=\"same\")\n",
    "        self.act1B = Activation(\"relu\")\n",
    "        self.bn1B = BatchNormalization(axis=chanDim)\n",
    "        self.pool1 = MaxPooling2D(pool_size=(2, 2))\n",
    "\n",
    "        # initialize the layers in the second (CONV => RELU) * 2 => POOL\n",
    "        # layer set\n",
    "        self.conv2A = Conv2D(32, (3, 3), padding=\"same\")\n",
    "        self.act2A = Activation(\"relu\")\n",
    "        self.bn2A = BatchNormalization(axis=chanDim)\n",
    "        self.conv2B = Conv2D(32, (3, 3), padding=\"same\")\n",
    "        self.act2B = Activation(\"relu\")\n",
    "        self.bn2B = BatchNormalization(axis=chanDim)\n",
    "        self.pool2 = MaxPooling2D(pool_size=(2, 2))\n",
    "\n",
    "        # initialize the layers in our fully-connected layer set\n",
    "        self.flatten = Flatten()\n",
    "        self.dense3 = Dense(512)\n",
    "        self.act3 = Activation(\"relu\")\n",
    "        self.bn3 = BatchNormalization()\n",
    "        self.do3 = Dropout(0.5)\n",
    "\n",
    "        # initialize the layers in the softmax classifier layer set\n",
    "        self.dense4 = Dense(classes)\n",
    "        self.softmax = Activation(\"softmax\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # build the first (CONV => RELU) * 2 => POOL layer set\n",
    "        x = self.conv1A(inputs)\n",
    "        x = self.act1A(x)\n",
    "        x = self.bn1A(x)\n",
    "        x = self.conv1B(x)\n",
    "        x = self.act1B(x)\n",
    "        x = self.bn1B(x)\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        # build the second (CONV => RELU) * 2 => POOL layer set\n",
    "        x = self.conv2A(x)\n",
    "        x = self.act2A(x)\n",
    "        x = self.bn2A(x)\n",
    "        x = self.conv2B(x)\n",
    "        x = self.act2B(x)\n",
    "        x = self.bn2B(x)\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        # build our FC layer set\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense3(x)\n",
    "        x = self.act3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.do3(x)\n",
    "\n",
    "        # build the softmax classifier\n",
    "        x = self.dense4(x)\n",
    "        x = self.softmax(x)\n",
    "\n",
    "        # return the constructed model\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22578"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Generate target classes\n",
    "\n",
    "classes = 101 #0 to 100\n",
    "target = wiki_df['age'].values           ### train/valid Y\n",
    "target_classes = keras.utils.to_categorical(target, classes)\n",
    "\n",
    "file_paths = wiki_df['full_path'].values ### train/valid X\n",
    "\n",
    "N_SAMPLES = len(target)\n",
    "\n",
    "assert(len(target) == len(file_paths))\n",
    "\n",
    "len(target_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load single image from disk to memmory\n",
    "# resize and convert to np array\n",
    "def load_img(x):\n",
    "    im = cv2.imread('../data/raw/wiki_crop/' + x)\n",
    "    im = cv2.resize(im, (224, 224), interpolation=cv2.INTER_LINEAR)\n",
    "    im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "    #im = im.reshape(1, -1)[0]\n",
    "    return (np.array(im) / 255.0).astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MiniVGGNetModel(\n",
    "    classes = classes)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "callbacks = [\n",
    "    #keras.callbacks.TensorBoard(\n",
    "    #    log_dir=os.path.join(\"logs\", timestamp()),\n",
    "    #    histogram_freq=1,\n",
    "    #    profile_batch=0)\n",
    "]\n",
    "\n",
    "# callbacks = []  # If you do not want to log results into TensorBoard\n",
    "\n",
    "scores = []\n",
    "epochs = 60\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples 22578\n"
     ]
    }
   ],
   "source": [
    "print(\"samples\", N_SAMPLES)\n",
    "\n",
    "train = 3000\n",
    "validation = 1000\n",
    "\n",
    "def load_image_data(files):\n",
    "    data = []\n",
    "    for file in files:\n",
    "        data.append(load_img(file))\n",
    "    return np.array(data)\n",
    "\n",
    "def load_data(range=(0,0)):\n",
    "    x = file_paths[range[0]:range[1]]\n",
    "    x = load_image_data(x)\n",
    "\n",
    "    # https://stackoverflow.com/questions/49083984/valueerror-can-not-squeeze-dim1-expected-a-dimension-of-1-got-3-for-sparse\n",
    "    # sparse_categorical_crossentropy\n",
    "    y = target[range[0]:range[1]] # target_classes\n",
    "    \n",
    "    return (x, y)\n",
    "    \n",
    "train_images, train_labels = load_data((0, train))\n",
    "test_images, test_labels = load_data((train, train+validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from: https://stackoverflow.com/a/55666861\n",
    "def change_to_right(wrong_labels):\n",
    "    right_labels=[]\n",
    "    for x in wrong_labels:\n",
    "        for i in range(0,len(wrong_labels[0])):\n",
    "            if x[i]==1:\n",
    "                right_labels.append(i)\n",
    "    return right_labels\n",
    "\n",
    "#train_labels = tf.convert_to_tensor(np.array(change_to_right(train_labels)))\n",
    "#test_labels = tf.convert_to_tensor(np.array(change_to_right(test_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3000 samples, validate on 1000 samples\n",
      "Epoch 1/60\n",
      "3000/3000 [==============================] - 256s 85ms/sample - loss: 5.1940 - accuracy: 0.1047 - val_loss: 5.5953 - val_accuracy: 0.0060\n",
      "Epoch 2/60\n",
      "3000/3000 [==============================] - 255s 85ms/sample - loss: 3.1931 - accuracy: 0.2913 - val_loss: 5.9673 - val_accuracy: 0.0010\n",
      "Epoch 3/60\n",
      "3000/3000 [==============================] - 263s 88ms/sample - loss: 1.7598 - accuracy: 0.6010 - val_loss: 6.2476 - val_accuracy: 0.0090\n",
      "Epoch 4/60\n",
      "3000/3000 [==============================] - 263s 88ms/sample - loss: 0.6561 - accuracy: 0.8723 - val_loss: 6.6410 - val_accuracy: 0.0270\n",
      "Epoch 5/60\n",
      "3000/3000 [==============================] - 262s 87ms/sample - loss: 0.2063 - accuracy: 0.9773 - val_loss: 5.2258 - val_accuracy: 0.0280\n",
      "Epoch 6/60\n",
      "3000/3000 [==============================] - 251s 84ms/sample - loss: 0.0747 - accuracy: 0.9960 - val_loss: 4.6817 - val_accuracy: 0.0300\n",
      "Epoch 7/60\n",
      "3000/3000 [==============================] - 244s 81ms/sample - loss: 0.0333 - accuracy: 0.9987 - val_loss: 4.6861 - val_accuracy: 0.0290\n",
      "Epoch 8/60\n",
      "3000/3000 [==============================] - 244s 81ms/sample - loss: 0.0206 - accuracy: 0.9997 - val_loss: 4.6358 - val_accuracy: 0.0290\n",
      "Epoch 9/60\n",
      "3000/3000 [==============================] - 252s 84ms/sample - loss: 0.0225 - accuracy: 0.9997 - val_loss: 4.6162 - val_accuracy: 0.0340\n",
      "Epoch 10/60\n",
      "3000/3000 [==============================] - 249s 83ms/sample - loss: 0.0143 - accuracy: 0.9997 - val_loss: 4.6858 - val_accuracy: 0.0370\n",
      "Epoch 11/60\n",
      "3000/3000 [==============================] - 244s 81ms/sample - loss: 0.0120 - accuracy: 0.9997 - val_loss: 4.7962 - val_accuracy: 0.0310\n",
      "Epoch 12/60\n",
      "3000/3000 [==============================] - 251s 84ms/sample - loss: 0.0142 - accuracy: 0.9993 - val_loss: 4.8832 - val_accuracy: 0.0340\n",
      "Epoch 13/60\n",
      "3000/3000 [==============================] - 251s 84ms/sample - loss: 0.0069 - accuracy: 0.9997 - val_loss: 4.9818 - val_accuracy: 0.0390\n",
      "Epoch 14/60\n",
      "3000/3000 [==============================] - 241s 80ms/sample - loss: 0.0046 - accuracy: 1.0000 - val_loss: 5.0508 - val_accuracy: 0.0400\n",
      "Epoch 15/60\n",
      "3000/3000 [==============================] - 241s 80ms/sample - loss: 0.0083 - accuracy: 0.9997 - val_loss: 5.1646 - val_accuracy: 0.0380\n",
      "Epoch 16/60\n",
      "3000/3000 [==============================] - 241s 80ms/sample - loss: 0.0050 - accuracy: 0.9997 - val_loss: 5.2385 - val_accuracy: 0.0380\n",
      "Epoch 17/60\n",
      "3000/3000 [==============================] - 239s 80ms/sample - loss: 0.0046 - accuracy: 0.9997 - val_loss: 5.2526 - val_accuracy: 0.0360\n",
      "Epoch 18/60\n",
      "3000/3000 [==============================] - 235s 78ms/sample - loss: 0.0063 - accuracy: 0.9993 - val_loss: 5.3042 - val_accuracy: 0.0380\n",
      "Epoch 19/60\n",
      "3000/3000 [==============================] - 240s 80ms/sample - loss: 0.0044 - accuracy: 0.9997 - val_loss: 5.3441 - val_accuracy: 0.0320\n",
      "Epoch 20/60\n",
      "3000/3000 [==============================] - 260s 87ms/sample - loss: 0.0035 - accuracy: 0.9997 - val_loss: 5.3501 - val_accuracy: 0.0360\n",
      "Epoch 21/60\n",
      "3000/3000 [==============================] - 267s 89ms/sample - loss: 0.0066 - accuracy: 0.9993 - val_loss: 5.4284 - val_accuracy: 0.0360\n",
      "Epoch 22/60\n",
      "3000/3000 [==============================] - 264s 88ms/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 5.4010 - val_accuracy: 0.0380\n",
      "Epoch 23/60\n",
      "3000/3000 [==============================] - 272s 91ms/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 5.4172 - val_accuracy: 0.0330\n",
      "Epoch 24/60\n",
      "3000/3000 [==============================] - 260s 87ms/sample - loss: 0.0032 - accuracy: 0.9997 - val_loss: 5.4928 - val_accuracy: 0.0350\n",
      "Epoch 25/60\n",
      "3000/3000 [==============================] - 259s 86ms/sample - loss: 0.0067 - accuracy: 0.9993 - val_loss: 5.5039 - val_accuracy: 0.0390\n",
      "Epoch 26/60\n",
      "3000/3000 [==============================] - 255s 85ms/sample - loss: 0.0044 - accuracy: 0.9993 - val_loss: 5.4768 - val_accuracy: 0.0390\n",
      "Epoch 27/60\n",
      "3000/3000 [==============================] - 260s 87ms/sample - loss: 0.0054 - accuracy: 0.9993 - val_loss: 5.5120 - val_accuracy: 0.0410\n",
      "Epoch 28/60\n",
      "3000/3000 [==============================] - 263s 88ms/sample - loss: 0.0043 - accuracy: 0.9993 - val_loss: 5.5046 - val_accuracy: 0.0430\n",
      "Epoch 29/60\n",
      "3000/3000 [==============================] - 254s 85ms/sample - loss: 0.0045 - accuracy: 0.9993 - val_loss: 5.6331 - val_accuracy: 0.0460\n",
      "Epoch 30/60\n",
      "3000/3000 [==============================] - 255s 85ms/sample - loss: 0.0042 - accuracy: 0.9997 - val_loss: 5.4918 - val_accuracy: 0.0410\n",
      "Epoch 31/60\n",
      "3000/3000 [==============================] - 259s 86ms/sample - loss: 0.0049 - accuracy: 0.9997 - val_loss: 5.5649 - val_accuracy: 0.0400\n",
      "Epoch 32/60\n",
      "3000/3000 [==============================] - 259s 86ms/sample - loss: 0.0044 - accuracy: 0.9997 - val_loss: 5.5221 - val_accuracy: 0.0430\n",
      "Epoch 33/60\n",
      "3000/3000 [==============================] - 256s 85ms/sample - loss: 0.0047 - accuracy: 0.9993 - val_loss: 5.4558 - val_accuracy: 0.0390\n",
      "Epoch 34/60\n",
      " 128/3000 [>.............................] - ETA: 3:45 - loss: 0.0014 - accuracy: 1.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-8007492bdb7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     epochs = epochs)\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/neural_networks_at_fiit/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.virtualenvs/neural_networks_at_fiit/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/neural_networks_at_fiit/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/neural_networks_at_fiit/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 86\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/neural_networks_at_fiit/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/neural_networks_at_fiit/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    485\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/neural_networks_at_fiit/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1821\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1823\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/neural_networks_at_fiit/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1141\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/neural_networks_at_fiit/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/neural_networks_at_fiit/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/.virtualenvs/neural_networks_at_fiit/lib/python3.6/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### train\n",
    "\n",
    "score = model.fit(\n",
    "    x=train_images,\n",
    "    y=train_labels,\n",
    "    batch_size = batch_size,\n",
    "    validation_data = (test_images, test_labels),\n",
    "    callbacks = callbacks,\n",
    "    epochs = epochs)\n",
    "\n",
    "scores.append(score)\n",
    "\n",
    "model.summary()  # Writes number of parameters for each layer at the end of the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 121s 4s/step - loss: 5.1736 - accuracy: 0.0290 - val_loss: 6.8492 - val_accuracy: 0.0100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f4bfc7781d0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_generator = WIKISequence(wiki_df[0:1000], 32)\n",
    "wiki_generator2 = WIKISequence(wiki_df[1000:1500], 32)\n",
    "\n",
    "model.fit_generator(\n",
    "    wiki_generator,\n",
    "     epochs=1,\n",
    "    validation_data=wiki_generator2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mini_vgg_net_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              multiple                  896       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      multiple                  0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo multiple                  128       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            multiple                  9248      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    multiple                  0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch multiple                  128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            multiple                  9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    multiple                  0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch multiple                  128       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            multiple                  9248      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    multiple                  0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch multiple                  128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 multiple                  0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  51380736  \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    multiple                  0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch multiple                  2048      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  51813     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    multiple                  0         \n",
      "=================================================================\n",
      "Total params: 51,463,749\n",
      "Trainable params: 51,462,469\n",
      "Non-trainable params: 1,280\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([ load_img(wiki_df['full_path'][0]) ])\n",
    "y = model.predict(x)\n",
    "\n",
    "np.argmax(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/viliam/.virtualenvs/neural_networks_at_fiit/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: ../models/mini-vgg-1.tf/assets\n"
     ]
    }
   ],
   "source": [
    "#Save model\n",
    "\n",
    "tf.keras.models.save_model(\n",
    "    model,\n",
    "    filepath = \"../models/mini-vgg-1.tf\",\n",
    "    overwrite=True,\n",
    "    include_optimizer=True,\n",
    "    save_format=\"tf\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 2\n",
    "Cely VGG model.\n",
    "\n",
    "Zdroj: https://sefiks.com/2018/08/06/deep-face-recognition-with-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.ZeroPadding2D((1,1),input_shape=(224,224, 3)))\n",
    "model.add(keras.layers.Convolution2D(64, (3, 3), activation='relu'))\n",
    "model.add(keras.layers.ZeroPadding2D((1,1)))\n",
    "model.add(keras.layers.Convolution2D(64, (3, 3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2), strides=(2,2)))\n",
    " \n",
    "model.add(keras.layers.ZeroPadding2D((1,1)))\n",
    "model.add(keras.layers.Convolution2D(128, (3, 3), activation='relu'))\n",
    "model.add(keras.layers.ZeroPadding2D((1,1)))\n",
    "model.add(keras.layers.Convolution2D(128, (3, 3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2), strides=(2,2)))\n",
    " \n",
    "model.add(keras.layers.ZeroPadding2D((1,1)))\n",
    "model.add(keras.layers.Convolution2D(256, (3, 3), activation='relu'))\n",
    "model.add(keras.layers.ZeroPadding2D((1,1)))\n",
    "model.add(keras.layers.Convolution2D(256, (3, 3), activation='relu'))\n",
    "model.add(keras.layers.ZeroPadding2D((1,1)))\n",
    "model.add(keras.layers.Convolution2D(256, (3, 3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2), strides=(2,2)))\n",
    " \n",
    "model.add(keras.layers.ZeroPadding2D((1,1)))\n",
    "model.add(keras.layers.Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(keras.layers.ZeroPadding2D((1,1)))\n",
    "model.add(keras.layers.Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(keras.layers.ZeroPadding2D((1,1)))\n",
    "model.add(keras.layers.Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2), strides=(2,2)))\n",
    " \n",
    "model.add(keras.layers.ZeroPadding2D((1,1)))\n",
    "model.add(keras.layers.Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(keras.layers.ZeroPadding2D((1,1)))\n",
    "model.add(keras.layers.Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(keras.layers.ZeroPadding2D((1,1)))\n",
    "model.add(keras.layers.Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2), strides=(2,2)))\n",
    " \n",
    "model.add(keras.layers.Convolution2D(4096, (7, 7), activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.5))\n",
    "model.add(keras.layers.Convolution2D(4096, (1, 1), activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.5))\n",
    "model.add(keras.layers.Convolution2D(2622, (1, 1)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('../data/vgg_face_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_face_descriptor = keras.Model(inputs=model.layers[0].input, outputs=model.layers[-1].output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert image as array using opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = 101 #0 to 100\n",
    "target = wiki_df['age'].values\n",
    "target_classes = keras.utils.to_categorical(target, classes)\n",
    "\n",
    "features = []\n",
    " \n",
    "for i in range(0, wiki_df.shape[0]):\n",
    "    features.append(wiki_df['img_array'].values[i])\n",
    " \n",
    "features = np.array(features)\n",
    "features = features.reshape(features.shape[0], 224, 224, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a0/c5/d2238762d780dde84a20b8c761f563fe882b88c5a5fb03c056547c442a19/scikit_learn-0.21.3-cp36-cp36m-manylinux1_x86_64.whl (6.7MB)\n",
      "\u001b[K     |████████████████████████████████| 6.7MB 4.7MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.17.2)\n",
      "Collecting joblib>=0.11 (from scikit-learn)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8f/42/155696f85f344c066e17af287359c9786b436b1bf86029bb3411283274f3/joblib-0.14.0-py2.py3-none-any.whl (294kB)\n",
      "\u001b[K     |████████████████████████████████| 296kB 28.7MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: joblib, scikit-learn\n",
      "Successfully installed joblib-0.14.0 scikit-learn-0.21.3\n",
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(features, target_classes, test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers[:-7]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_output = keras.models.Sequential()\n",
    "base_model_output = keras.layers.Convolution2D(101, (1, 1), name='predictions')(model.layers[-4].output)\n",
    "base_model_output = keras.layers.Flatten()(base_model_output)\n",
    "base_model_output = keras.layers.Activation('softmax')(base_model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_model = keras.Model(inputs=model.input, outputs=base_model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  0\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "epochs = 250; batch_size = 50\n",
    " \n",
    "for i in range(epochs):\n",
    "    print(\"epoch \",i)\n",
    " \n",
    "    ix_train = np.random.choice(train_x.shape[0], size=batch_size)\n",
    " \n",
    "    score = age_model.fit(train_x[ix_train], train_y[ix_train], epochs=1, validation_data=(test_x, test_y))\n",
    " \n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
