{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyyaml\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/e8/b3212641ee2718d556df0f23f78de8303f068fe29cdaa7a91018849582fe/PyYAML-5.1.2.tar.gz (265kB)\n",
      "\u001b[K     |████████████████████████████████| 266kB 4.9MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.17.2)\n",
      "Collecting scipy\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/72/a26272b99220804038d8ac4aabe8383cfd969ec548695b0df258058ee919/scipy-1.3.2-cp36-cp36m-manylinux1_x86_64.whl (25.2MB)\n",
      "\u001b[K     |████████████████████████████████| 25.2MB 31.8MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (3.1.1)\n",
      "Requirement already satisfied: ipython in /usr/local/lib/python3.6/dist-packages (7.8.0)\n",
      "Requirement already satisfied: jupyter in /usr/local/lib/python3.6/dist-packages (1.0.0)\n",
      "Collecting pandas\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/52/3f/f6a428599e0d4497e1595030965b5ba455fd8ade6e977e3c819973c4b41d/pandas-0.25.3-cp36-cp36m-manylinux1_x86_64.whl (10.4MB)\n",
      "\u001b[K     |████████████████████████████████| 10.4MB 16.4MB/s eta 0:00:01    |████████████████████▎           | 6.6MB 16.4MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting sympy\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/21/21/f4105795ca7f35c541d82c5b06be684dd2f5cb4f508fb487cd7aea4de776/sympy-1.4-py2.py3-none-any.whl (5.3MB)\n",
      "\u001b[K     |████████████████████████████████| 5.3MB 22.2MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nose\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/15/d8/dd071918c040f50fa1cf80da16423af51ff8ce4a0f2399b7bf8de45ac3d9/nose-1.3.7-py3-none-any.whl (154kB)\n",
      "\u001b[K     |████████████████████████████████| 163kB 39.5MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting opencv-python\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/7e/bd5425f4dacb73367fddc71388a47c1ea570839197c2bcad86478e565186/opencv_python-4.1.1.26-cp36-cp36m-manylinux1_x86_64.whl (28.7MB)\n",
      "\u001b[K     |████████████████████████████████| 28.7MB 28.2MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting opencv-contrib-python\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/33/9b/1f9ef069206002d0bbca80598193904ce1ae2a990e7465bc351b1264c7d8/opencv_contrib_python-4.1.1.26-cp36-cp36m-manylinux1_x86_64.whl (34.7MB)\n",
      "\u001b[K     |████████████████████████████████| 34.7MB 1.2MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting imutils\n",
      "  Downloading https://files.pythonhosted.org/packages/b5/94/46dcae8c061e28be31bcaa55c560cb30ee9403c9a4bb2659768ec1b9eb7d/imutils-0.5.3.tar.gz\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.4.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.8.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: jedi>=0.10 in /usr/local/lib/python3.6/dist-packages (from ipython) (0.15.1)\n",
      "Requirement already satisfied: backcall in /usr/local/lib/python3.6/dist-packages (from ipython) (0.1.0)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython) (0.7.5)\n",
      "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython) (41.2.0)\n",
      "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython) (4.3.2)\n",
      "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython) (4.7.0)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython) (4.4.0)\n",
      "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from ipython) (2.0.9)\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython) (2.4.2)\n",
      "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from jupyter) (5.6.0)\n",
      "Requirement already satisfied: qtconsole in /usr/local/lib/python3.6/dist-packages (from jupyter) (4.5.5)\n",
      "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.6/dist-packages (from jupyter) (6.0.0)\n",
      "Requirement already satisfied: ipykernel in /usr/local/lib/python3.6/dist-packages (from jupyter) (5.1.2)\n",
      "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.6/dist-packages (from jupyter) (7.5.1)\n",
      "Requirement already satisfied: notebook in /usr/local/lib/python3.6/dist-packages (from jupyter) (6.0.1)\n",
      "Collecting pytz>=2017.2 (from pandas)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e7/f9/f0b53f88060247251bf481fa6ea62cd0d25bf1b11a87888e53ce5b7c8ad2/pytz-2019.3-py2.py3-none-any.whl (509kB)\n",
      "\u001b[K     |████████████████████████████████| 512kB 29.4MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting mpmath>=0.19 (from sympy)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/63/3384ebb3b51af9610086b23ea976e6d27d6d97bf140a76a365bd77a3eb32/mpmath-1.1.0.tar.gz (512kB)\n",
      "\u001b[K     |████████████████████████████████| 522kB 29.5MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.1->matplotlib) (1.11.0)\n",
      "Requirement already satisfied: parso>=0.5.0 in /usr/local/lib/python3.6/dist-packages (from jedi>=0.10->ipython) (0.5.1)\n",
      "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython) (0.2.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython) (0.6.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython) (0.1.7)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter) (1.4.2)\n",
      "Requirement already satisfied: nbformat>=4.4 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter) (4.4.0)\n",
      "Requirement already satisfied: jinja2>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter) (2.10.1)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter) (0.8.4)\n",
      "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter) (0.4.2)\n",
      "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter) (0.6.0)\n",
      "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter) (4.5.0)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter) (0.3)\n",
      "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter) (3.1.0)\n",
      "Requirement already satisfied: jupyter-client>=4.1 in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter) (5.3.3)\n",
      "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipykernel->jupyter) (6.0.3)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->jupyter) (3.5.1)\n",
      "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter) (1.5.0)\n",
      "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter) (0.8.2)\n",
      "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter) (0.7.1)\n",
      "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter) (18.1.0)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.4->nbconvert->jupyter) (3.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2>=2.4->nbconvert->jupyter) (1.1.1)\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->jupyter) (0.5.1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.4->nbconvert->jupyter) (19.2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyrsistent>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.4->nbconvert->jupyter) (0.15.4)\n",
      "Building wheels for collected packages: pyyaml, imutils, mpmath\n",
      "  Building wheel for pyyaml (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyyaml: filename=PyYAML-5.1.2-cp36-cp36m-linux_x86_64.whl size=45393 sha256=aaf6725e2e693cdfa305c5742c54b522d3bb503be8370354071dda92d0568700\n",
      "  Stored in directory: /root/.cache/pip/wheels/d9/45/dd/65f0b38450c47cf7e5312883deb97d065e030c5cca0a365030\n",
      "  Building wheel for imutils (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for imutils: filename=imutils-0.5.3-cp36-none-any.whl size=26734 sha256=d8a837b0849f7e111ee2aeb7c46ed429e7ebf5f9b57253211963b4bf889eb9fc\n",
      "  Stored in directory: /root/.cache/pip/wheels/16/84/1f/bf88641293cda2c8be81a5c4b8ca973dd9125a6dc3767417fd\n",
      "  Building wheel for mpmath (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for mpmath: filename=mpmath-1.1.0-cp36-none-any.whl size=532006 sha256=4bf41778a0dd8d674b142ed6212ec02a1d5754a31cc9882dd0123eb6ce2b431a\n",
      "  Stored in directory: /root/.cache/pip/wheels/63/9d/8e/37c3f6506ed3f152733a699e92d8e0c9f5e5f01dea262f80ad\n",
      "Successfully built pyyaml imutils mpmath\n",
      "Installing collected packages: pyyaml, scipy, pytz, pandas, mpmath, sympy, nose, opencv-python, opencv-contrib-python, imutils\n",
      "Successfully installed imutils-0.5.3 mpmath-1.1.0 nose-1.3.7 opencv-contrib-python-4.1.1.26 opencv-python-4.1.1.26 pandas-0.25.3 pytz-2019.3 pyyaml-5.1.2 scipy-1.3.2 sympy-1.4\n",
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pyyaml numpy scipy matplotlib ipython jupyter pandas sympy nose opencv-python opencv-contrib-python imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "\n",
    "import yaml\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.01, 'batch_size': 16, 'num_hidden_layers': 4}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hparams = yaml.safe_load(open('../src/models/hparams.yaml'))\n",
    "\n",
    "hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_path</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>img_array</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17/10000217_1981-05-05_2009.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28</td>\n",
       "      <td>[255 255 255 ... 144  78  27]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12/100012_1948-07-03_2008.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60</td>\n",
       "      <td>[92 98 93 ... 35 31 30]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16/10002116_1971-05-31_2012.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41</td>\n",
       "      <td>[ 10  30  61 ... 231 237 255]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>02/10002702_1960-11-09_2012.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52</td>\n",
       "      <td>[178 122  97 ... 168 112  83]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41/10003541_1937-09-27_1971.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34</td>\n",
       "      <td>[194 189 190 ... 101 103 104]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         full_path  gender  age                      img_array\n",
       "0  17/10000217_1981-05-05_2009.jpg     1.0   28  [255 255 255 ... 144  78  27]\n",
       "1    12/100012_1948-07-03_2008.jpg     1.0   60        [92 98 93 ... 35 31 30]\n",
       "2  16/10002116_1971-05-31_2012.jpg     0.0   41  [ 10  30  61 ... 231 237 255]\n",
       "3  02/10002702_1960-11-09_2012.jpg     0.0   52  [178 122  97 ... 168 112  83]\n",
       "4  41/10003541_1937-09-27_1971.jpg     1.0   34  [194 189 190 ... 101 103 104]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_df = pd.read_csv('../data/processed/wiki_df.csv', sep=';')\n",
    "\n",
    "wiki_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "wiki_df['img_array'] = wiki_df['full_path'].apply(lambda x: cv2.resize(cv2.imread('../data/raw/wiki_crop/' + x), (224, 224), interpolation=cv2.INTER_LINEAR).reshape(1, -1)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1\n",
    "\n",
    "* Ako prvé sa pokúsime vytvoriť NN podobnú VGG. Podľa [WEEK_7 lab](https://github.com/matus-pikuliak/neural_networks_at_fiit/blob/92b24eef8e6444c43a22e8fa51a349b3b1043a7c/week_7/week_7.ipynb), alebo iného tutoriálu\n",
    "* Natrénujeme ju na už predspracovanom datasete\n",
    "* Jej výsledok pou%zijeme ako štartovaciu čiaru\n",
    "* Túto sieť budeme rozširovať o ďalšie vrstvy a parametre\n",
    "* V projekte ponecháme sieť s najlepším skóre\n",
    "* Dole pripájam referenčnú ukážku siete. [Zdroj](https://www.pyimagesearch.com/2019/10/28/3-ways-to-create-a-keras-model-with-tensorflow-2-0-sequential-functional-and-model-subclassing/?__s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiniVGGNetModel(keras.Model):\n",
    "    def __init__(self, classes, chanDim=-1):\n",
    "        # call the parent constructor\n",
    "        super(MiniVGGNetModel, self).__init__()\n",
    "\n",
    "        # initialize the layers in the first (CONV => RELU) * 2 => POOL\n",
    "        # layer set\n",
    "        self.conv1A = Conv2D(32, (3, 3), padding=\"same\")\n",
    "        self.act1A = Activation(\"relu\")\n",
    "        self.bn1A = BatchNormalization(axis=chanDim)\n",
    "        self.conv1B = Conv2D(32, (3, 3), padding=\"same\")\n",
    "        self.act1B = Activation(\"relu\")\n",
    "        self.bn1B = BatchNormalization(axis=chanDim)\n",
    "        self.pool1 = MaxPooling2D(pool_size=(2, 2))\n",
    "\n",
    "        # initialize the layers in the second (CONV => RELU) * 2 => POOL\n",
    "        # layer set\n",
    "        self.conv2A = Conv2D(32, (3, 3), padding=\"same\")\n",
    "        self.act2A = Activation(\"relu\")\n",
    "        self.bn2A = BatchNormalization(axis=chanDim)\n",
    "        self.conv2B = Conv2D(32, (3, 3), padding=\"same\")\n",
    "        self.act2B = Activation(\"relu\")\n",
    "        self.bn2B = BatchNormalization(axis=chanDim)\n",
    "        self.pool2 = MaxPooling2D(pool_size=(2, 2))\n",
    "\n",
    "        # initialize the layers in our fully-connected layer set\n",
    "        self.flatten = Flatten()\n",
    "        self.dense3 = Dense(512)\n",
    "        self.act3 = Activation(\"relu\")\n",
    "        self.bn3 = BatchNormalization()\n",
    "        self.do3 = Dropout(0.5)\n",
    "\n",
    "        # initialize the layers in the softmax classifier layer set\n",
    "        self.dense4 = Dense(classes)\n",
    "        self.softmax = Activation(\"softmax\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # build the first (CONV => RELU) * 2 => POOL layer set\n",
    "        x = self.conv1A(inputs)\n",
    "        x = self.act1A(x)\n",
    "        x = self.bn1A(x)\n",
    "        x = self.conv1B(x)\n",
    "        x = self.act1B(x)\n",
    "        x = self.bn1B(x)\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        # build the second (CONV => RELU) * 2 => POOL layer set\n",
    "        x = self.conv2A(x)\n",
    "        x = self.act2A(x)\n",
    "        x = self.bn2A(x)\n",
    "        x = self.conv2B(x)\n",
    "        x = self.act2B(x)\n",
    "        x = self.bn2B(x)\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        # build our FC layer set\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense3(x)\n",
    "        x = self.act3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.do3(x)\n",
    "\n",
    "        # build the softmax classifier\n",
    "        x = self.dense4(x)\n",
    "        x = self.softmax(x)\n",
    "\n",
    "        # return the constructed model\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 2\n",
    "Cely VGG model.\n",
    "\n",
    "Zdroj: https://sefiks.com/2018/08/06/deep-face-recognition-with-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.ZeroPadding2D((1,1),input_shape=(224,224, 3)))\n",
    "model.add(keras.layers.Convolution2D(64, (3, 3), activation='relu'))\n",
    "model.add(keras.layers.ZeroPadding2D((1,1)))\n",
    "model.add(keras.layers.Convolution2D(64, (3, 3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2), strides=(2,2)))\n",
    " \n",
    "model.add(keras.layers.ZeroPadding2D((1,1)))\n",
    "model.add(keras.layers.Convolution2D(128, (3, 3), activation='relu'))\n",
    "model.add(keras.layers.ZeroPadding2D((1,1)))\n",
    "model.add(keras.layers.Convolution2D(128, (3, 3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2), strides=(2,2)))\n",
    " \n",
    "model.add(keras.layers.ZeroPadding2D((1,1)))\n",
    "model.add(keras.layers.Convolution2D(256, (3, 3), activation='relu'))\n",
    "model.add(keras.layers.ZeroPadding2D((1,1)))\n",
    "model.add(keras.layers.Convolution2D(256, (3, 3), activation='relu'))\n",
    "model.add(keras.layers.ZeroPadding2D((1,1)))\n",
    "model.add(keras.layers.Convolution2D(256, (3, 3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2), strides=(2,2)))\n",
    " \n",
    "model.add(keras.layers.ZeroPadding2D((1,1)))\n",
    "model.add(keras.layers.Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(keras.layers.ZeroPadding2D((1,1)))\n",
    "model.add(keras.layers.Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(keras.layers.ZeroPadding2D((1,1)))\n",
    "model.add(keras.layers.Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2), strides=(2,2)))\n",
    " \n",
    "model.add(keras.layers.ZeroPadding2D((1,1)))\n",
    "model.add(keras.layers.Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(keras.layers.ZeroPadding2D((1,1)))\n",
    "model.add(keras.layers.Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(keras.layers.ZeroPadding2D((1,1)))\n",
    "model.add(keras.layers.Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2), strides=(2,2)))\n",
    " \n",
    "model.add(keras.layers.Convolution2D(4096, (7, 7), activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.5))\n",
    "model.add(keras.layers.Convolution2D(4096, (1, 1), activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.5))\n",
    "model.add(keras.layers.Convolution2D(2622, (1, 1)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('../data/vgg_face_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_face_descriptor = keras.Model(inputs=model.layers[0].input, outputs=model.layers[-1].output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert image as array using opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = 101 #0 to 100\n",
    "target = wiki_df['age'].values\n",
    "target_classes = keras.utils.to_categorical(target, classes)\n",
    "\n",
    "features = []\n",
    " \n",
    "for i in range(0, wiki_df.shape[0]):\n",
    "    features.append(wiki_df['img_array'].values[i])\n",
    " \n",
    "features = np.array(features)\n",
    "features = features.reshape(features.shape[0], 224, 224, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a0/c5/d2238762d780dde84a20b8c761f563fe882b88c5a5fb03c056547c442a19/scikit_learn-0.21.3-cp36-cp36m-manylinux1_x86_64.whl (6.7MB)\n",
      "\u001b[K     |████████████████████████████████| 6.7MB 4.7MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.17.2)\n",
      "Collecting joblib>=0.11 (from scikit-learn)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8f/42/155696f85f344c066e17af287359c9786b436b1bf86029bb3411283274f3/joblib-0.14.0-py2.py3-none-any.whl (294kB)\n",
      "\u001b[K     |████████████████████████████████| 296kB 28.7MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: joblib, scikit-learn\n",
      "Successfully installed joblib-0.14.0 scikit-learn-0.21.3\n",
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(features, target_classes, test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers[:-7]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_output = keras.models.Sequential()\n",
    "base_model_output = keras.layers.Convolution2D(101, (1, 1), name='predictions')(model.layers[-4].output)\n",
    "base_model_output = keras.layers.Flatten()(base_model_output)\n",
    "base_model_output = keras.layers.Activation('softmax')(base_model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_model = keras.Model(inputs=model.input, outputs=base_model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  0\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "epochs = 250; batch_size = 50\n",
    " \n",
    "for i in range(epochs):\n",
    "    print(\"epoch \",i)\n",
    " \n",
    "    ix_train = np.random.choice(train_x.shape[0], size=batch_size)\n",
    " \n",
    "    score = age_model.fit(train_x[ix_train], train_y[ix_train], epochs=1, validation_data=(test_x, test_y))\n",
    " \n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
